{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Task description:\n",
        "- Modify the ResNet example from the book to resemble the\n",
        "Network from the paper \"Wide Residual Networks\" by Zagoruyko et al.\n",
        "\n",
        "- Use the same augmentation methods as in the paper\n",
        "(RandomHorizontalFlip and RandomCrop)\n",
        "- Compare the accuracy (detection rates) for training and validation data with the\n",
        "validation data with the example from the book\n",
        "- Train the network only for the classification of birds and airplanes.\n",
        "- Use 28 B(3,3) layers with k=2\n",
        "\n",
        "# Implementation:"
      ],
      "metadata": {
        "id": "ssQsiSETi6LS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0zhtJLr0yvIw",
        "outputId": "febcfcb2-318a-4d75-cac9-cc11be7e0cec"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbfb858d210>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RBug_S-Yzbra",
        "outputId": "88e64ff2-9d37-4ca0-af6b-7808124117ec"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]\n"
      ],
      "metadata": {
        "id": "-kD0Ezxozeir"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training loop\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            outputs = outputs[:len(labels)]\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "MB_47MGPzq-G"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validates the accuracy of a given model on training and validation data\n",
        "# and stores the results in a dictionary\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)  # <1>\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                outputs = outputs[:len(labels)]\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict"
      ],
      "metadata": {
        "id": "L_Y0ePWtzt4i"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ResNetDeep()"
      ],
      "metadata": {
        "id": "BzuDvQVYwf6x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# copied from the Book Deep-Learning with Pytorch by Eli Stevens for comparison to own implemented network WideResidualNetwork\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv = nn.Conv2d(n_chans, n_chans, kernel_size=3,\n",
        "                              padding=1, bias=False)  # <1>\n",
        "        self.batch_norm = nn.BatchNorm2d(num_features=n_chans)\n",
        "        torch.nn.init.kaiming_normal_(self.conv.weight,\n",
        "                                      nonlinearity='relu')  # <2>\n",
        "        torch.nn.init.constant_(self.batch_norm.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv(x)\n",
        "        out = self.batch_norm(out)\n",
        "        out = torch.relu(out)\n",
        "        return out + x\n",
        "\n",
        "\n",
        "class NetResDeep(nn.Module):\n",
        "    def __init__(self, n_chans1=32, n_blocks=10):\n",
        "        super().__init__()\n",
        "        self.n_chans1 = n_chans1\n",
        "        self.conv1 = nn.Conv2d(3, n_chans1, kernel_size=3, padding=1)\n",
        "        self.resblocks = nn.Sequential(\n",
        "            *(n_blocks * [ResBlock(n_chans=n_chans1)]))\n",
        "        self.fc1 = nn.Linear(8 * 8 * n_chans1, 32)\n",
        "        self.fc2 = nn.Linear(32, 2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.max_pool2d(torch.relu(self.conv1(x)), 2)\n",
        "        out = self.resblocks(out)\n",
        "        out = F.max_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * self.n_chans1)\n",
        "        out = torch.relu(self.fc1(out))\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "NGU4iF1TkPHf"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')\n",
        "print(\"ResNetDeep from Book Deep-Learning with PyTorch by Eli Stevens:\")\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "model = NetResDeep(n_chans1=32, n_blocks=28).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)\n",
        "print(\"Number of free parameters in the model:\",sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBoIHv1Bk9nZ",
        "outputId": "631b5dfb-86fe-41b8-b258-f1c2f1b7fe32"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNetDeep from Book Deep-Learning with PyTorch by Eli Stevens:\n",
            "2023-06-19 13:06:53.768692 Epoch 1, Training loss 0.6870595774832805\n",
            "2023-06-19 13:07:18.718525 Epoch 10, Training loss 0.3088138674854473\n",
            "2023-06-19 13:07:46.773646 Epoch 20, Training loss 0.21589484877267462\n",
            "2023-06-19 13:08:14.338897 Epoch 30, Training loss 0.15515167994578932\n",
            "2023-06-19 13:08:41.756228 Epoch 40, Training loss 0.12364577526926615\n",
            "2023-06-19 13:09:09.126357 Epoch 50, Training loss 0.07961698998489482\n",
            "2023-06-19 13:09:36.559698 Epoch 60, Training loss 0.11591702577165643\n",
            "2023-06-19 13:10:04.195961 Epoch 70, Training loss 0.01145614955572791\n",
            "2023-06-19 13:10:31.507238 Epoch 80, Training loss 0.08479479701809917\n",
            "2023-06-19 13:10:58.840804 Epoch 90, Training loss 0.03849992383817199\n",
            "2023-06-19 13:11:26.195553 Epoch 100, Training loss 0.18032954080374378\n",
            "Accuracy train: 0.98\n",
            "Accuracy val: 0.86\n",
            "Number of free parameters in the model: 75810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### WideResidualNetwork()"
      ],
      "metadata": {
        "id": "v-tDSskLwZRN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definieren der Modellarchitektur des Wide Residual Networks\n",
        "class WideResidualBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1):\n",
        "        super(WideResidualBlock, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm2d(in_channels)\n",
        "        self.relu1 = nn.ReLU(inplace=True)\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu2 = nn.ReLU(inplace=True)\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.downsample = None\n",
        "\n",
        "        # Check if downsample is needed based on input and output channels and stride\n",
        "        if in_channels != out_channels or stride != 1:\n",
        "            self.downsample = nn.Sequential(\n",
        "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        # First convolutional block\n",
        "        out = self.bn1(x)\n",
        "        out = self.relu1(out)\n",
        "        out = self.conv1(out)\n",
        "\n",
        "        # Second convolutional block\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu2(out)\n",
        "        out = self.conv2(out)\n",
        "\n",
        "        # Apply downsample if necessary\n",
        "        # adjust the dimensions of the input feature map so that it matches the dimensions of the output feature map\n",
        "        if self.downsample is not None:\n",
        "            identity = self.downsample(x)\n",
        "\n",
        "        # Add identity to output\n",
        "        out += identity\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class WideResidualNetwork(nn.Module):\n",
        "    def __init__(self, num_blocks, width, num_classes=2):\n",
        "        super(WideResidualNetwork, self).__init__()\n",
        "        # Initial convolutional layer\n",
        "        self.conv1 = nn.Conv2d(3, 16 * width, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        # Three blocks of WideResidualBlock modules\n",
        "        self.block0 = self._make_block_seq(16 * width, 16 * width, num_blocks)\n",
        "        self.block1 = self._make_block_seq(16 * width, 32 * width, num_blocks, stride=2)\n",
        "        self.block2 = self._make_block_seq(32 * width, 64 * width, num_blocks, stride=2)\n",
        "        self.blocks = [self.block0, self.block1, self.block2]\n",
        "\n",
        "        # Batch normalization, average pooling, and fully connected layers\n",
        "        self.bn = nn.BatchNorm2d(64 * width)\n",
        "        self.avg_pool = nn.AvgPool2d(8, stride=1)\n",
        "        self.fcl = nn.Linear(64 * width, num_classes)\n",
        "\n",
        "    def _make_block_seq(self, in_channels, out_channels, num_blocks, stride=1):\n",
        "        block_seq = []\n",
        "        # Create the WideResidualBlock bock sequences\n",
        "        block_seq.append(WideResidualBlock(in_channels, out_channels, stride))\n",
        "        for _ in range(1, num_blocks):\n",
        "            block_seq.append(WideResidualBlock(out_channels, out_channels))\n",
        "        return nn.Sequential(*block_seq)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Input convolutional layer\n",
        "        x = self.conv1(x)\n",
        "        # Pass through each block in the WideResidualNetwork\n",
        "        for block in self.blocks:\n",
        "          x = block(x)\n",
        "        # Batch normalization, activation, pooling, flattening, and fully connected layers\n",
        "        x = self.bn(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fcl(x)\n",
        "        return x\n",
        "\n"
      ],
      "metadata": {
        "id": "hpinp_tpzp74"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"WideResidualNetwork from Paper Wide Residual Networks by Zagoruyko et al.:\")\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "model = WideResidualNetwork(num_blocks=4, width=2, num_classes=2).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-1)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 100,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)\n",
        "print(\"Number of free parameters in the model:\",sum(p.numel() for p in model.parameters()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdJQAI8WzzC0",
        "outputId": "65480938-96bd-49f1-9f40-d108491b25a0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WideResidualNetwork from Paper Wide Residual Networks by Zagoruyko et al.:\n",
            "2023-06-19 13:24:48.440499 Epoch 1, Training loss 0.46060856208679785\n",
            "2023-06-19 13:25:36.739702 Epoch 10, Training loss 0.16452496980500828\n",
            "2023-06-19 13:26:29.759600 Epoch 20, Training loss 0.030695219507891756\n",
            "2023-06-19 13:27:23.236152 Epoch 30, Training loss 0.0020471766195204375\n",
            "2023-06-19 13:28:16.483703 Epoch 40, Training loss 0.01093795595121137\n",
            "2023-06-19 13:29:09.644597 Epoch 50, Training loss 0.0036373017630038397\n",
            "2023-06-19 13:30:02.857480 Epoch 60, Training loss 0.0003268259985764121\n",
            "2023-06-19 13:30:56.091691 Epoch 70, Training loss 6.868609134355766e-05\n",
            "2023-06-19 13:31:49.144783 Epoch 80, Training loss 7.751022358959768e-05\n",
            "2023-06-19 13:32:42.302052 Epoch 90, Training loss 3.812436228342049e-05\n",
            "2023-06-19 13:33:35.495770 Epoch 100, Training loss 3.922447275883291e-05\n",
            "Accuracy train: 1.00\n",
            "Accuracy val: 0.92\n",
            "Number of free parameters in the model: 1471138\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparison:\n",
        "\n",
        "The NetResDeep network uses simple residual blocks consisting of a convolutional layer and a batch normalization layer. These blocks are connected several times in series to achieve a deeper architecture. It has a comparatively small number of parameters (75,810) and consists of a single convolutional layer followed by residual blocks and a linear classification layer. The accuracy of the NetResDeep model is 98% on the training data and 86% on the validation data.\n",
        "\n",
        "The WideResidualNetwork, on the other hand, uses Wide Residual Blocks, which have a wider network architecture with more channels. These blocks consist of two convolutional layers and are deeper than the simple residual blocks. The WideResidualNetwork has a much higher number of parameters (1,471,138) due to the larger number of channels in the blocks. It also has a Convolutional layer followed by three layers of Wide Residual Blocks, Batch Normalization, Pooling, and a Linear Classification layer. The WideResidualNetwork has a broader and deeper architecture that allows the model to capture more features and learn more complex relationships in the data. This leads to higher accuracy on the validation data, as can also be seen here: the accuracy of the WideResidualNetwork model is 100% on the training data and 92% on the validation data."
      ],
      "metadata": {
        "id": "foINrudEv8ju"
      }
    }
  ]
}