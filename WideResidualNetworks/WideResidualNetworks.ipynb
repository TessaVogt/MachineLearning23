{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rmHHUNTgArw",
        "outputId": "f47dca35-3892-4619-83fb-819efb222747"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f50701c4e90>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "import datetime\n",
        "import random\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']\n",
        "\n",
        "data_path = '../data-unversioned/p1ch6/'\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    data_path, train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))\n",
        "\n",
        "cifar10_val = datasets.CIFAR10(\n",
        "    data_path, train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WItwjp86gDKx",
        "outputId": "09177764-b337-4fee-ea90-7062c8045de4"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "label_map = {0: 0, 2: 1}\n",
        "class_names = ['airplane', 'bird']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10\n",
        "          if label in [0, 2]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [0, 2]]\n"
      ],
      "metadata": {
        "id": "jMBh-2ukgTU2"
      },
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, n_chans, widen_factor):\n",
        "        super(ResBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(n_chans * widen_factor, n_chans * widen_factor, kernel_size=3,\n",
        "                               padding=1, bias=False)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(num_features=n_chans * widen_factor)\n",
        "        self.conv2 = nn.Conv2d(n_chans * widen_factor, n_chans * widen_factor, kernel_size=3,\n",
        "                               padding=1, bias=False)\n",
        "        self.batch_norm2 = nn.BatchNorm2d(num_features=n_chans * widen_factor)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
        "                                      nonlinearity='relu')\n",
        "        torch.nn.init.kaiming_normal_(self.conv2.weight,\n",
        "                                      nonlinearity='relu')\n",
        "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
        "        torch.nn.init.constant_(self.batch_norm2.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
        "        torch.nn.init.zeros_(self.batch_norm2.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.batch_norm1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv1(out)\n",
        "        out = self.batch_norm2(out)\n",
        "        out = self.relu(out)\n",
        "        out = self.conv2(out)\n",
        "        out += x\n",
        "        return out\n",
        "\n",
        "\n",
        "class NetResDeep(nn.Module):\n",
        "    def __init__(self, width, n_blocks):\n",
        "        super(NetResDeep, self).__init__()\n",
        "        self.width = width\n",
        "        self.conv1 = nn.Conv2d(3, 16 * width, kernel_size=3, padding=1)\n",
        "        self.batch_norm1 = nn.BatchNorm2d(num_features=16 * width)\n",
        "        resblocks = []\n",
        "        for _ in range(n_blocks):\n",
        "            resblocks.append(ResBlock(16, widen_factor=width))\n",
        "        self.resblocks = nn.Sequential(*resblocks)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16 * width, 500)\n",
        "        self.fc2 = nn.Linear(500, 2)\n",
        "\n",
        "        torch.nn.init.kaiming_normal_(self.conv1.weight,\n",
        "                                      nonlinearity='relu')\n",
        "        torch.nn.init.kaiming_normal_(self.fc1.weight,\n",
        "                                      nonlinearity='relu')\n",
        "        torch.nn.init.constant_(self.batch_norm1.weight, 0.5)\n",
        "        torch.nn.init.zeros_(self.batch_norm1.bias)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.conv1(x)  # Eingabe durch Conv1 leiten\n",
        "        out = self.batch_norm1(out)  # Batch-Normalization auf Conv1-Ausgabe anwenden\n",
        "        out = F.relu(out)  # ReLU-Aktivierung auf Conv1-Ausgabe anwenden\n",
        "        out = F.avg_pool2d(out, 2)  # Average-Pooling auf Conv1-Ausgabe mit Fenstergröße 2x2 anwenden\n",
        "        out = self.resblocks(out)  # Ausgabe von Max-Pooling durch die Sequenz der Residual-Blöcke leiten\n",
        "        # out = self.batch_norm1(out)  # Batch-Normalization auf Conv1-Ausgabe anwenden\n",
        "        # out = F.relu(out)  # ReLU-Aktivierung auf Conv1-Ausgabe anwenden\n",
        "        out = F.avg_pool2d(out, 2)\n",
        "        out = out.view(-1, 8 * 8 * 16 * self.width)  # Ausgabe der letzten Max-Pooling-Schicht in einen Vektor umformen\n",
        "        out = F.relu(self.fc1(out))  # Ausgabe der linearen Schicht fc1 durch ReLU-Aktivierung leiten\n",
        "        out = self.fc2(out)  # Ausgabe der linearen Schicht fc2 erhalten\n",
        "        return out\n"
      ],
      "metadata": {
        "id": "Ylr9zJfNo2ou"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the training loop\n",
        "def training_loop(n_epochs, optimizer, model, loss_fn, train_loader):\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        loss_train = 0.0\n",
        "\n",
        "        for imgs, labels in train_loader:\n",
        "            imgs = imgs.to(device=device)  # <1>\n",
        "            labels = labels.to(device=device)\n",
        "            outputs = model(imgs)\n",
        "            outputs = outputs[:len(labels)]\n",
        "            loss = loss_fn(outputs, labels)\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            loss_train += loss.item()\n",
        "\n",
        "        if epoch == 1 or epoch % 10 == 0:\n",
        "            print('{} Epoch {}, Training loss {}'.format(\n",
        "                datetime.datetime.now(), epoch,\n",
        "                loss_train / len(train_loader)))"
      ],
      "metadata": {
        "id": "sb0UZ08dgXkn"
      },
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# validates the accuracy of a given model on training and validation data\n",
        "# and stores the results in a dictionary\n",
        "def validate(model, train_loader, val_loader):\n",
        "    accdict = {}\n",
        "    for name, loader in [(\"train\", train_loader), (\"val\", val_loader)]:\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for imgs, labels in loader:\n",
        "                imgs = imgs.to(device=device)  # <1>\n",
        "                labels = labels.to(device=device)\n",
        "                outputs = model(imgs)\n",
        "                outputs = outputs[:len(labels)]\n",
        "                _, predicted = torch.max(outputs, dim=1) # <1>\n",
        "                total += labels.shape[0]\n",
        "                correct += int((predicted == labels).sum())\n",
        "\n",
        "        print(\"Accuracy {}: {:.2f}\".format(name , correct / total))\n",
        "        accdict[name] = correct / total\n",
        "    return accdict"
      ],
      "metadata": {
        "id": "OROxDAEXgaq_"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda')"
      ],
      "metadata": {
        "id": "8WHt7uq-hG_j"
      },
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(cifar2_val, batch_size=64, shuffle=False)\n",
        "all_acc_dict = collections.OrderedDict()\n",
        "\n",
        "model = NetResDeep(width=2, n_blocks=14).to(device=device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=3e-3)\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "training_loop(\n",
        "    n_epochs = 20,\n",
        "    optimizer = optimizer,\n",
        "    model = model,\n",
        "    loss_fn = loss_fn,\n",
        "    train_loader = train_loader,\n",
        ")\n",
        "all_acc_dict[\"res deep\"] = validate(model, train_loader, val_loader)\n",
        "print(\"Number of free parameters in the model:\",sum(p.numel() for p in model.parameters()))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nVqZoBeLgbxW",
        "outputId": "b057faae-25a5-4365-bc4d-e51e8295136e"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-06-14 14:58:30.118135 Epoch 1, Training loss 0.5484911881055042\n",
            "2023-06-14 14:58:54.086111 Epoch 10, Training loss 0.28675311167908324\n",
            "2023-06-14 14:59:20.708086 Epoch 20, Training loss 0.18180611952664746\n",
            "Accuracy train: 0.93\n",
            "Accuracy val: 0.85\n",
            "Number of free parameters in the model: 1286302\n"
          ]
        }
      ]
    }
  ]
}